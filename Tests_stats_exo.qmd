---
title: "Tests stats"
format: 
  html:
    toc: true
runtime: shiny_prerendered
css: "www/style_tuto_learnr.css"
---

<!-- learnr::tutorial: -->
<!--     progressive: true -->
<!--     allow_skip: true -->

```{r setup, include=FALSE}
library(learnr)
library(gradethis)

Sys.setlocale("LC_ALL", "fr_FR.UTF-8")
gradethis_setup()
 
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(gridExtra)
library(purrr)
library(magrittr)
library(gganimate)
library(infer)
source("scripts/utils.R")
#knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)

chateauxEtBoulots=read.table("datasets/chateauxEtBoulots.csv",header=TRUE,sep=";")
broceliande=read.csv("datasets/broceliande.csv",sep=";", header=T)
potions=read.csv("datasets/potions.csv",sep=";", header=T)
```


## 1. Introduction 

### 1.0 Préambule

![](www/grimoire.png){width=400px}

Les explications et données d'exemple pour ce tutoriel proviennent de <a href="http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/_book/intro.html" target="_blank">cet ouvrage en ligne</a> (notamment le Chapitre 4 *Etablir le lien entre deux variables: tests d’hypothèse*). Vous pouvez également y trouver des chapitres portant sur d'autres méthodes classiques en statistique (description simple de variables, estimateurs, intervalles de confiance, modèles de régression, analyse de la variance, modèle linéaire généralisé).

### 1.1 Exercices de code

Ce document rassemble un certain nombre d'exercices, qui sont de **deux types**.

- Des exercices de type **QCM**.
- Des exercices de type **code**.


Dans ce deuxième type d'exercice, vous pourrez **modifier du code** dans une fenêtre (fond jaune pâle) qui est l'équivalent d'un **éditeur** (très simplifié) de code R. Pour **exécuter** les lignes de code, vous pouvez vous placer dessus et faire **Ctrl+Enter**. Le résultat s'affichera dans une fenêtre (fond rose pâle) en-dessous qui est l'équivalent d'une **console** R.

La consigne pour cet exercice d'exemple est la suivante:

Calculez le produit de a et b (qui ont été préalablement définis dans l'environnement).

```{r,decouvre_exos-setup}
a=33
b=29
```

```{r decouvre_exos, exercise=TRUE}
produit=___
produit
```

```{r decouvre_exos-solution}
produit=a*b
produit
```

```{r decouvre_exos-check}
grade_result(pass_if(~identical(produit,957),
                     "Très bien! Le résultat du code correspond bien à la valeur 22"),
             fail_if(~!identical(produit,957),
                     "Ah non! le résultat du code ne correspond pas à la valeur attendue..."))
```


Le code que vous entrerez peut être évalué automatiquement lorsque vous appuyez sur **Submit solution**. 

L'évaluation porte usuellement sur la dernière commande écrite dans l'éditeur (celle écrite tout en bas!), ainsi que (plus généralement) sur le fait que le code ne génère pas d'erreur lors de son exécution.

Par exemple, l'exercice ci-dessus est paramétré pour être évalué comme correct quand la dernière commande (donc d'après le code pré-renseigné l'objet `produit`) correspond à la valeur 957, et incorrect autrement... Vous pouvez corriger (ou non) le code dans l'éditeur pour tester le comportement de l'évaluation...

Dans ce tutoriel l'**environnement R est propre à chaque exercice**, et je le prépare pour qu'il contienne les **objets** (par exemple jeux de données) et les **packages**  nécessaires, installés et chargés.

### 1.2 Exercices type QCM

```{r usages_R}
question("Que pouvez-vous faire avec R?",
    answer("Des modèles", correct=TRUE),
    answer("Des simulations", correct=TRUE),
    answer("Des statistiques", correct=TRUE),
    answer("Du café"),
    answer("Des graphiques", correct=TRUE),
    answer("Des rapports", correct = TRUE),
    answer("Des pains au chocolat"),
    answer("Des diaporamas", correct=TRUE),
    incorrect="Seules deux de ces propositions ne sont pas correctes",
    correct="Oui! C'est dommage pour le café mais il faut bien une motivation pour se lever de son fauteuil de temps en temps...",
    allow_retry=TRUE
)
```

<!-- ### 1.4 Assignation -->

<!-- Testez les commandes suivantes.  -->

<!-- Modifiez le code **pour que `obj_d` fasse également partie de l'environnement** et soit listé lors de l'appel de `ls()`. -->


<!-- ```{r assignation, exercise=TRUE, exercise.lines=8} -->
<!-- obj_a <- "coin-coin" -->
<!-- obj_b <- "pouet-pouet" -->
<!-- obj_c = 25.7 -->
<!-- #obj_d <- 33 -->
<!-- ls() -->
<!-- ``` -->

<!-- ```{r assignation-solution} -->
<!-- obj_a <- "coin-coin" -->
<!-- obj_b <- "pouet-pouet" -->
<!-- obj_c = 25.7 -->
<!-- obj_d <- 33 -->
<!-- ls() -->
<!-- ``` -->

<!-- ```{r assignation-check} -->
<!-- grade_result( -->
<!--   fail_if(~isFALSE("obj_d" %in% .result), "Non, l'objet obj_d ne fait toujours pas partie de l'environnement"), -->
<!--   pass_if(~isTRUE("obj_d" %in% .result), -->
<!--           "Eh oui! Avant que vous dé-commentiez la ligne, le vecteur `obj_d` n'était pas créé."), -->
<!--   fail_if(~ TRUE, "ça fonctionne pas") -->
<!-- ) -->
<!-- ``` -->


### 1.3 Jeu de données Brocéliande

<table>
  <col width="40%">
  <col width="60%">
<tr><td>
<img src="www/enchanted_tree.png"  width="200px"></img>
</td>
<td>
Le jeu de données `broceliande` recense (en terme d'individus) un certain nombre d'arbres de la forêt de Brocéliande ainsi que (en terme de variables):

- `age`: leur âge, en années
- `espece`: leur espèce (chêne, châtaignier, hêtre ou sapin)
- `hauteur`: leur hauteur, en cm
- `largeur`: leur largeur, en cm
- `gui`: le nombre de touffes de gui qui les affecte
- `enchantement`: la présence d'un enchantement sur cet arbre (TRUE ou FALSE)
- `fees`: le nombre de fées qui habitent cet arbre
- `lutins`: le nombre de lutins qui habitent cet arbre
- `perlimpinpin`: la quantité de poudre de perlimpinpin dans sa sève (en $\mu$g/L)

</td></tr></table>

Le jeu de données `broceliande` est disponible en ligne [à cette adresse](datasets/broceliande.csv).

```{r broceliande_pres}
broceliande=read.csv("http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/datasets/broceliande.csv",
                     header=TRUE,sep=";")
str(broceliande)
```

L'objectif des tests d'hypothèse est de déterminer si un **effet observé à l'échelle de l'échantillon** résulte d'un **effet réel à l'échelle de la population**, autrement dit, il s'agit de déterminer si l'effet observé est **significatif** et non pas simplement lié à l'**aléa d'échantillonnage**.


### 1.4 Jeu de données Châteaux et Boulots

<table>
  <col width="40%">
  <col width="60%">
<tr><td>
<img src="www/chateau.png"  width="200px"></img>
</td>
<td>
Le jeu de données `chateauxEtBoulots` recense (en terme d'individus) un certain nombre de personnes du pays Fantaisie ainsi que (en terme de variables)

- `activite`: leur activité (la royauté, la chevalerie, les enchantements ou la magie noire),
- `sexe`: leur sexe (féminin ou masculin),
- `region`: leur région (Bois-Jolis,Montage-Sombre ou Flots-Blancs)
- `tenue`: leur couleur de tenue (noire, grise, bleue, verte, ou rose).

</td>
</tr>
</table>


Le jeu de données `chateauxEtBoulots` est disponible en ligne [à cette adresse](datasets/chateauxEtBoulots.csv).

```{r chateauxEtBoulots_pres}
chateauxEtBoulots=read.csv("http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/datasets/chateauxEtBoulots.csv",
                           header=TRUE, sep=";")
str(chateauxEtBoulots)
```


## 2. Test de Student 
### 2.1 Principe

Bien qu'il existe une multitude de tests d'hypothèses (test de Student, test du Chi-2, test de Mann-Whitney, etc. en fonction du type de données et de la problématique considérés), la logique et les "mécanismes d'interprétation" sont toujours les mêmes...

Je vais donc décrire en détail les idées sous-jacente à un test statistique, en développant l'exemple d'un test particulier, le **t-test**. 

Le **t-test** (ou **test de Student**) est conçu pour tester des **différences de moyennes entre deux groupes**.


<table>
  <col width="150">
  <col width="300">
<tr><td>
<img src="www/balance.png"  width="300"></img>
</td>
<td>
Par exemple, on cherche à caractériser la **quantité de poudre de perlimpinpin dans un arbre** en fonction de la **nature enchantée ou non** de celui-ci.
</td>
</tr>
</table>

```{r boxplot_ench_perl_2, fig.width=5, fig.height=3}
ggplot(broceliande, aes(x=enchantement, y=perlimpinpin))+
  geom_violin(fill="lightblue")+
  geom_point(data=broceliande %>% group_by(enchantement) %>% summarise(perlimpinpin=mean(perlimpinpin)), col="red")
```
```{r}
broceliande %>% 
  group_by(enchantement) %>% 
  summarise(moy_perlimpinpin=mean(perlimpinpin),
            n=n())
```

A la vue du graphique et du tableau ci-dessus, on a bien l'impression que la quantité de perlimpinpin est plus importante pour les arbres enchantés que pour les autres... ?


```{r inference_mentale, }
question("mais est-ce un effet réel ou simplement dû au hasard, à votre avis? (plusieurs réponses possibles)",
    answer("Probablement lié au hasard, car les distributions des deux groupes ne sont pas disjointes."),
    answer("Probablement lié au hasard, car les échantillons sont de tailles très inégales."),
    answer("Probablement réel, car les tailles d'échantillon sont relativement importantes", correct=TRUE),
    answer("Probablement réel, car les distributions semblent à peu près gaussiennes", correct=TRUE),
    incorrect="Eh non, a priori les distributions par groupe et les tailles d'échantillon iraient plutôt dans le sens d'un effet réel, mais on ne peut pas vous tenir rigueur de ne pas savoir faire d'inférence au doigt mouillé",
    correct="Oui! Vu les tailles d'échantillon importantes et les distributions qui semblent à peu près gaussiennes, on peut penser que l'effet observé est réel. Mais on va quand-même essayer de le faire de manière rigoureuse ;-)",
    allow_retry=TRUE
)
```




### 2.2 Théorie

Je "conceptualise" mon problème par le modèle suivant: 

<div class="encadre">
$perlimpinpin$ a une distribution $\mathcal{N}(\mu_e,\sigma_e)$ pour les arbres enchantés, et $\mathcal{N}(\mu_f,\sigma_f)$ pour les autres.
</div>

Je définis mon hypothèse:

<div class="encadre">
$H_0:\{\mu_e=\mu_f\}$ 
</div>

Selon cette hypothèse, il n'y a **pas de différence réelle** de moyenne entre les deux groupes (même si, de facto, il y a une différence *observée*).

Autrement dit, l'hypothèse que je cherche à tester statistiquement est celle selon laquelle "la quantité de perlimpinpin moyenne n'est pas différente selon les groupes" ... 

alors que mon hypothèse au sens "scientifique" était plutôt l'hypothèse inverse puisque j'ai en réalité l'intention de prouver que l'enchantement **a un effet significatif sur la quantité de perlimpinpin**!... Il faut donc faire attention à ne pas se mélanger les pinceaux... 

Considérons la statistique suivante:

<div class="encadre">

$$
T=\frac{\bar X_e-\bar X_f}{\sqrt{\frac{s_e^2}{n_e}+\frac{s_f^2}{n_f}}}=\frac{\bar X_e-\bar X_f}{\sqrt{eqm_e+eqm_f}}
$$
</div>

où

- $\bar{X_e}$ et $\bar{X_f}$ sont les estimateurs de la moyenne (par groupe)
- $s_e$ et $s_f$ sont les estimateurs des écarts-types (par groupe)
- $n_e$ et $n_f$ sont les effectifs observés (par groupe)

Cette métrique est donc d'autant plus grande (en valeur absolue) que 

- l'écart entre moyennes est important,
- les tailles d'échantillons sont importantes,
- la variance au sein de chaque groupe est petite.

<div class="encadre">
Si notre hypothèse $H_0$ était vraie alors cette statistique $T$ devrait suivre une **distribution de Student** avec $\nu$ degrés de liberté.
</div>

(Il s'agit d'un résultat **mathématique**, que je ne démontrerai pas ici!)

Le **paramètre $\nu$** correspond à:

$$
\nu=\frac{\left(\frac{s_e^2}{n_e}+\frac{s_f^2}{n_f}\right)^2}{{(\frac{s_e^2}{n_e})}^2\frac{1}{n_e-1}+{(\frac{s_f^2}{n_f})}^2 \frac{1}{n_f-1}}=\frac{(eqm_e+eqm_f)^2}{eqm_e^2\ \frac{1}{n_e-1}+eqm_f^2\ \frac{1}{n_f-1}}
$$




On peut calculer les valeurs $t_{obs}$ (valeur de $T$ pour les observations) et $\nu$ "à la main":

```{r broc_ttest_calc_alamain, echo=TRUE}
broc_test=broceliande %>%
  group_by(enchantement) %>% 
  summarise(m=mean(perlimpinpin),
            s2=sd(perlimpinpin)^2,
            n=n()) %>% 
  mutate(eqm=s2/n,
         w=1/(n-1)) %>% 
  mutate(eqmw=w*eqm^2)
valeurs_obs=broc_test %>%
  summarise(t_obs=diff(m)/sqrt(sum(eqm)),
            nu=sum(eqm)^2/sum(eqmw))
valeurs_obs
```

Voici donc la distribution de Student à $\nu$=`r round(valeurs_obs$nu)` degrés de liberté (i.e. la distribution que $T$ doit suivre, théoriquement, si l'hypothèse $H_0$ est vraie): 

```{r broc_ttest_calc_infer, echo=FALSE, fig.width=5, fig.height=2.5}
broceliande %>%
  specify(perlimpinpin ~ enchantement) %>%
  hypothesize(null = "independence") %>% 
  calculate(stat = "t") %>% 
  visualize(method = "theoretical")
```

Par rapport à cette **distribution théorique de $T$ "sous hypothèse $H_0$"**, voilà comment se situe la **valeur observée de T pour notre échantillon ($t_{obs}$)**:

```{r broc_ttest_calc_infer_et_obs, echo=FALSE, fig.width=5, fig.height=2.5}
mytest <- broceliande %>% 
  t_test(formula = perlimpinpin ~ enchantement, order=c(TRUE,FALSE))
t_obs=mytest%>% 
  select(statistic) %>% 
  pull()
broceliande %>%
  specify(perlimpinpin ~ enchantement) %>%
  hypothesize(null = "independence") %>% 
  calculate(stat = "t") %>% 
  visualize(method = "theoretical",
            obs_stat=t_obs,
            direction = "two_sided")
```

Comme on peut le voir sur ce graphique, la valeur que l'on observe pour T est plutôt "excentrée" par rapport à la distribution théorique sous hypothèse $H_0$. 

En effet, la **probabilité d'observer une valeur au moins aussi excentrée (à droite ou à gauche) sous hypothèse $H_0$**, ou **p-value** est de:

```{r calc_ttest_pval_alamain}
2*(1-pt(valeurs_obs$t_obs,valeurs_obs$nu))
```

C'est cette valeur de probabilité qui est représentée par la surface coloriée en rouge dans le graphique ci-dessus.

Si la p-value est particulièrement petite, cela tend à prouver que **la valeur observée de $T$ est peu probable sous hypothèse $H_0$**. Cela amène donc à remettre en question l'hypothèse (et non l'observation!!).

En dessous d'un certain seuil pour cette probabilité (par exemple, $\alpha=5$\%), on décide de rejeter l'hypothèse $H_0$. Dans ce cas on peut affirmer qu'il existe bien un effet significatif de `enchantement` sur `perlimpinpin`.

La valeur $\alpha$ est souvent, par convention, 5\% (il arrive aussi que l'on voie 10\%, 1\%, etc.). Cette valeur **n'est pas un repère absolu** (si vous êtes à 5.1\% plutôt qu'à 4.9\% ça ne devrait pas *fondamentalement* changer votre conclusion...).

### 2.3 Erreurs 

Erreurs associées à un test d'hypothèse

Cette valeur seuil $\alpha$ abordée précédemment correspond en fait à un risque d'erreur de type I que l'on est "prêt à accepter".

<div class="encadre">
Faire une **erreur de type I**, ça consiste à **rejeter l'hypothèse nulle alors qu'elle est vraie** (c'est-à-dire, affirmer qu'une différence est significative alors que ce n'est pas le cas). Le **risque d'erreur de type I** est souvent noté $\alpha$

Faire une **erreur de type II**, au contraire, ça consiste à **ne pas rejeter l'hypothèse nulle alors qu'elle est fausse** (c'est-à-dire, ne pas conclure que la différence est significative alors qu'elle existe vraiment). Le **risque d'erreur de type II** est souvent noté $\beta$.


Cas            |  $H_0$ rejetée              | $H_0$ acceptée
---------------|-----------------------------|---------------
$H_0$ vraie    | erreur de type I ($\alpha$) | CORRECT
$H_0$ fausse   |  CORRECT                    | erreur de type II ($\beta$)

La **puissance d'un test** est égale à 1-$\beta$ i.e. elle correspond à la probabilité de détecter un effet quand il existe ($H_0$ est fausse et onR rejette $H_0$).

</div>

Quand on choisit de réaliser un test avec un risque $\alpha$ particulièrement bas, alors le risque $\beta$ est particulièrement élevé: alors on le fait au détriment de la **puissance** du test (c'est-à-dire que plus on minimise le risque de dire qu'il y a un effet alors qu'il n'y en a pas, plus on maximise le risque de "passer à côté" d'un effet qui existe).

### 2.4 Pratique

En pratique, pour réaliser un t-test sous R, on n'a pas besoin de faire à la main toutes les étapes du calcul détaillé dans le paragraphe précédent (ouf!). Il existe *évidemment* des fonctions dans R pour faciliter la tâche.

La fonction de base est `t.test()`:

```{r myttest,type="essentiel", echo=TRUE}
mytest=t.test(perlimpinpin~enchantement, data=broceliande)
print(mytest)
```

Plusieurs informations s'affichent:

- le **nom du test** (t-test de Welch pour deux échantillons)
- certains **éléments** qui interviennent dans le calcul d'une **p-value** (valeur de métrique observée t, nombre de degrés de liberté df) 
- la **p-value** elle-même
- l'hypothèse alternative (et non pas $H_0$) selon laquelle la différence de moyenne entre les groupes **n'est pas** égale à 0
- un **intervalle de confiance à 95\% pour cette différence de moyenne**
- les **moyennes estimées** pour chaque groupe

On retrouve notamment la valeur $t_{obs}$, $\nu$ (nombre de degrés de liberté) et la p-value calculés "à la main" dans le paragraphe précédent:

```{r myttest_detail}
mytest$p.value
mytest$statistic
mytest$t_df
```


## 3. Validité du t-test

### 3.1 Package infer

Outre la fonction t.test de "base", il est également possible d'utiliser le package "infer" pour réaliser un t-test "à la tidyverse":

```{r myttest_infer, fig.width=5, fig.height=2.5}
mytest <- broceliande %>% 
  t_test(formula = perlimpinpin ~ enchantement, order=c(TRUE,FALSE))
print(mytest)

t_obs=mytest%>% 
  select(statistic) %>% 
  pull()
print(t_obs)

broceliande %>%
  specify(perlimpinpin ~ enchantement) %>%
  hypothesize(null = "independence") %>% 
  calculate(stat = "t") %>% 
  visualize(method = "theoretical",
            obs_stat=t_obs,
            direction = "two_sided")

```

<div class="exo">

Considérez le jeu de données `broceliande`. Nous allons nous intéresser à deux sous-populations distinctes: 

- les chênes d'une part, 
- les sapins d'autre part.

Pour l'une et l'autre de ces populations, l'enchantement a-t-il une influence sur la quantité de perlimpinpin?

```{r, echo=FALSE, results=FALSE}
t.test(perlimpinpin~enchantement, data=filter(broceliande,espece=="chene"))
t.test(perlimpinpin~enchantement, data=filter(broceliande,espece=="sapin"))
```


</div>


### 3.1 Conditions de validité

Revenons aux conditions nécessaires à la validité du t-test.

Rappelez-vous comment j'ai spécifié mon modèle:

<div class="encadre">
$perlimpinpin$ a une distribution $\mathcal{N}(\mu_e,\sigma_e)$ pour les arbres enchantés, et $\mathcal{N}(\mu_f,\sigma_f)$ pour les autres.
</div>

Ainsi, on connaît la distribution de la statistique $T$ sous hypothèse $H_0$, mais aussi sous réserve que la distribution de $perlimpinpin$ dans chaque groupe défini par $enchantement$ soit **normale** (i.e. gaussienne).

![](www/chapeaux.png)

Que se passe-t-il si ce n'est pas le cas? (... et en l'occurrence, **ce n'est pas le cas**). Voyez plutôt, si l'on réaliste un test de Shapiro-Wilk pour tester la normalité des données (pour chaque groupe), ce test rejette l'hypothèse de distribution normale de perlimpinpin pour les arbres non-enchantés:

```{r shapiro}
# arbres enchantés
shapiro.test(filter(broceliande,enchantement)$perlimpinpin)
# arbres non-enchantés
shapiro.test(filter(broceliande,!enchantement)$perlimpinpin)
```


En fait, comme dans le cas du **Théorème Central Limite**, quand bien même l'hypothèse de normalité des résidus ne serait pas respectée, la distribution de $T$ tend bien vers une distribution de Student à $\nu$ degrés de liberté **pour des tailles d'échantillon "suffisamment grandes"**.

Tout le sel de la situation consiste à estimer la valeur pour laquelle on estime que la taille d'échantillon est "suffisamment grande" (ce seuil étant d'autant plus élevé que la distribution des résidus est éloignée de la distribution normale) pour pouvoir appliquer le t-test quand bien-même l'hypothèse de normalité ne serait pas respecté...

Le package `infer` permet  de travailler assez facilement **non pas sur une distribution théorique de la statistique $T$** (reposant, donc, sur un modèle de distribution supposé) mais sur la **distribution observée de $T$ quand on réalise des permutations**.

Le principe des permutations réalisées ici est de réaliser de nombreuses fois l'opération suivante:

- étiqueter au hasard les individus selon les **modalités de la variable définissant les groupes** (et selon les effectifs observés)
- calculer la **statistique $T$** pour ce jeu de données (généré, donc, sous hypothèse que la variable qui définit le groupe et la réponse quantitative soient indépendants)

On obtient ainsi la **distribution de la statistique $T$ sous hypothèse d'indépendance** pour les distributions observées.

```{r infer_permutations_ttest, fig.width=5, fig.height=2.5}
permutations=broceliande %>% 
  specify(perlimpinpin ~ enchantement) %>% 
  hypothesize(null="independence") %>% 
  generate(reps=1000,type="permute") %>% 
  calculate(stat="t", order=c(FALSE,TRUE)) %>% 
  visualize(method="simulation",
            obs_stat=t_obs,
            direction="two_sided")

```

Ici on constate que la significativité du résultat ne fait pas de doute!


### 3.2 Généralisation

Principe général d'un test d'hypothèse *paramétrique*

<div class="encadre">
- On considère un **modèle statistique** décrivant nos données
- On considère une certaine **hypothèse** $H_0$ concernant les paramètres du modèle
- On considère une **métrique $S$** (il s'agit d'une *variable aléatoire*), dont la nature dépend du test réalisé.
-  On calcule sa **distribution théorique** en se basant sur le modèle assorti de l'hypothèse $H_0$. 
- On calcule la **valeur prise par $S$ pour les observations**: on obtient ainsi la mesure **$S_{obs}$**. $S_{obs}$ est une *réalisation* de la variable $S$.
- On regarde **où se place $S_{obs}$ par rapport à distribution théorique de $S$**: on calcule la probabilité que $S$ soit au moins aussi "extrême" que $S_{obs}$. C'est cette probabilité qui constitue la **p-value**.
</div>

Dans tous les cas, lorsque l'on réalise un test statistique, il faut être très attentif aux éléments suivants:

- Les hypothèses du modèle sous-jacent au test (par exemple, pour le t-test, la variable d'intérêt doit être de distribution gaussienne. En revanche, le fait que vous utilisiez le t-test de Welch et non de Student vous permet de supposer que la variance est différente dans les deux groupes)
- La nature de l'hypothèse $H_0$ (Si vous vous trompez sur la nature de cette hypothèse, alors vous vous tromperez dans la manière dont vous interprétez les résultats du test!)



## 4. Test du Chi-2 

                                      
### 4.1 Principe

Intéressons-nous au jeu de données `chateauxEtBoulots`, et au lien entre `sexe` et `activite`.


```{r chateauxEtBoulots_barplot_1, fig.width=6,fig.height=2}
#| code-fold: true
ggplot(chateauxEtBoulots,aes(x=activite))+
  geom_bar(aes(fill=sexe))
```

```{r chateauxEtBoulots_barplot_2, fig.width=6,fig.height=2}
ggplot(chateauxEtBoulots,aes(x=activite))+
  geom_bar(aes(fill=sexe),position="fill")
```


### 4.2 Tableau de contingence {.tab}

Nous avons-vu que la comparaison entre le tableau des effectifs croisés **observés** et des effectifs **attendus** sous hypothèse d'indépendance pouvait nous renseigner sur un lien éventuel entre les deux variables considérées. 

En l'occurrence, on peut noter les **effectifs observés** dans chacune des J cases du tableau $\bar {N_i}$ et les **effectifs attendus** $N_i$.

A partir de ces deux tableaux, une **statistique du Chi-2** (écrite $\chi^2$) peut être calculée et utilisée pour tester l'hypothèse d'indépendance entre les deux variables catégorielles. La statistique du $\chi^2$ correspond à :

$$\chi^2=\sum_{i=1}^{J}\frac{(\bar{N_i}-N_i)^2}{N_i}$$
**Sous hypothèse d'indépendance**, et sous réserve que les effectifs par case soient suffisamment importants, cette statistique $\chi^2$ est censée suivre une **distribution du $\chi^2$ à $J-2$ degrés de liberté**.

C'est ce résultat (mathématique) qui permet de fournir une **p-value** qui correspond à la **probabilité d'obtenir une valeur de $\chi^2$ supérieure à celle qui est calculée sur les observations**.

### 4.3 Pratique

Faire un test du Chi-2 sous R

<table>
  <col width="40%">
  <col width="60%">
  <tr>
  <td><img src="www/trone.png" width="200px" </td>
  <td>Examinons par exemple le jeu de données `chateauxEtBoulots` et plus particulièrement le lien entre le sexe et l'activité de nos personnages de contes de fée... On a vu en section \@ref(tableaucontingences) comment **décrire le lien** entre ces deux variables catégorielles par un **tableau de contingences**. Voyons maintenant comment l'on peut **tester la significativité de ce lien**.</td>
  </tr>
</table>

```{r chateauxEtBoulots_chisq_en_pratique}
montest=chisq.test(table(chateauxEtBoulots$sexe,chateauxEtBoulots$activite))
print(montest)
```

Ici la p-value est très petite, montrant (comme on s'y attendait) que les deux variables **ne sont pas indépendantes**.

On peut examiner plus avant les éléments renvoyés par ce test de la manière suivante:

```{r chisqtest_elems}
names(montest)
```

On retrouve ainsi, entre autres choses, des éléments d'information concernant

- les **effectifs observés**


```{r chisqtest_observed}
montest$observed
```

- les **effectifs attendus sous hypothèse d'indépendance**

```{r chisqtest_expected}
montest$expected
```


<div class="exo">

Considérez le tableau `chateauxEtBoulots` et les variables `tenue` et `region`. Les tendances en terme de couleurs de tenue sont-elles bien significativement différentes en fonction de la région de Fantaisie?...

```{r, echo=FALSE, results=FALSE}
chisq.test(table(chateauxEtBoulots$tenue,chateauxEtBoulots$region))
```

</div>


## 5 Validité du test du Chi-2

### 5.1 Petits effectifs 

Un test du $\chi^2$ est construit en supposant que **les effectifs $\bar N_j$ sont "suffisants")**. Ainsi, quand certaines cases du tableau de contingence comprennent trop peu d'individus, appliquer un test du $\chi^2$ peut causer un "warning" stipulant que *l'approximation du $\chi^2$ peut être incorrecte*.

Conidérons par exemple un sous-jeu de données de `chateauxEtBoulots` rassemblant uniquement les individus de noble extraction, et intéressons-nous au lien entre leur sexe et leur couleur de tenue:

```{r chateauxEtBoulots_princiere}
tenue_princiere=filter(chateauxEtBoulots, activite=="royaute") %>% 
  mutate(tenue=as.factor(as.vector(tenue)))

table_tenue_princiere=table(tenue_princiere$sexe, tenue_princiere$tenue)
table_tenue_princiere


chisq.test(table_tenue_princiere)
```

Ici, on a bien des effectifs réduits qui causent le renvoi d'un warning...

Le package `infer` permet, dans ce genre de situation, de **calculer une p-value en passant par des permutations** plutôt qu'en utilisant la distribution de la statistique du $\chi^2$ qui s'applique pour des effectifs observés importants.

Le principe des permutations réalisées ici est de réaliser de nombreuses fois l'opération suivante:

- étiqueter au hasard les individus selon les **modalités du premier facteur** (et selon les effectifs observés pour celui-ci)
- étiqueter au hasard les individus selon les **modalités du second facteur** (et selon les effectifs observés pour celui-ci)
- calculer la **statistique du $chi^2$** pour ce jeu de données (généré, donc, sous hypothèse que les deux facteurs soient indépendants)

On obtient ainsi la **distribution de la statistique $chi^2$ sous hypothèse d'indépendance** pour les effectifs observés de l'un et l'autre facteur (aussi déséquilibrés et faibles soient-ils).

La valeur observée du $\chi^2$ sur les données est la suivante:

```{r infer_obs_chisq, warning=FALSE, message=FALSE}
obs_chisq=tenue_princiere %>% 
  chisq_test(formula=tenue~sexe) %>% 
  select(statistic) %>% 
  pull()

obs_chisq # pareil que chisq.test(tenue_princiere)$statistic, mais obtenu via infer

```

On simule 1000 jeux de données différents à partir du jeu de données `sim_princiere` selon la méthode expliquée ci-dessus. On obtient ainsi 1000 valeurs de la statistique $\chi^2$:

```{r infer_generate_chisq}
sim_princiere=tenue_princiere %>%
  specify(tenue~sexe) %>% 
  hypothesize(null="independence") %>%
  generate(reps=1000, type="permute") %>% 
  calculate(stat="Chisq") 

head(sim_princiere)
```

Cela permet de décrire la distribution de la statistique $\chi^2$ et d'en déduire une p-value:

```{r sim_princiere_visu, fig.width=5, fig.height=2.5}
resume_sim_princiere=
  sim_princiere %>%
  mutate(case=stat<obs_chisq) %>% 
  group_by(case) %>% 
  summarise(prop=n()) %>% 
  mutate(prop=prop/1000)
resume_sim_princiere

sim_princiere%>% 
  visualize(obs_stat=obs_chisq, direction="greater")
```

On obtient ainsi la distribution réelle de la statistique du $\chi^2$ sous hypothèse d'indépendance, et la valeur de la p-value (`r resume_sim_princiere$prop[1]`). Ici, on remarque que la p-value est quasiment inchangée selon la méthode de calcul (distribution théorique ou par permutations)! On n'est pas en mesure d'affirmer que la couleur de tenue des princes et princesses dépend de leur sexe.


<div class="exo">

On reprend l'exercice précédent...

Considérez le tableau `chateauxEtBoulots` et les variables `tenue` et `region`. Les tendances en terme de couleurs de tenue sont-elles bien significativement différentes en fonction de la région de Fantaisie?...

Répondez à cette question à l'aide du package `infer` et des permutations, de sorte de ne pas être gêné par le faible effectif dans certaines cases du tableau de contingence...

```{r, echo=FALSE, results=FALSE}
obs_chisq=tenue_princiere %>% 
  chisq_test(formula=tenue~region) %>% 
  select(statistic) %>% 
  pull()

obs_chisq # pareil que chisq.test(tenue_princiere)$statistic, mais obtenu via infer
sim_princiere=tenue_princiere %>%
  specify(tenue~sexe) %>% 
  hypothesize(null="independence") %>%
  generate(reps=1000, type="permute") %>% 
  calculate(stat="Chisq") 

head(sim_princiere)
resume_sim_princiere=
  sim_princiere %>%
  mutate(case=stat<obs_chisq) %>% 
  group_by(case) %>% 
  summarise(prop=n()) %>% 
  mutate(prop=prop/1000)
resume_sim_princiere

sim_princiere%>% 
  visualize(obs_stat=obs_chisq, direction="greater")
```

</div>



## ANNEXE


```{r eval=FALSE}
grade_this({
  lobjs <- ls(envir = .envir_result)
  if (!exists("starks", envir = .envir_result) ) {
    fail("La table `starks` n'existe pas.")
  }
  if (!identical(.result,.solution)) {
    fail("Ce résultat n'est pas ce que j'attendais. Vérifiez les valeurs...")
  }
  if (identical(.result,.solution)) {
    pass("Bravo ! Vous avez bien créé la table `starks`, avec les valeurs attendues")
  }
})
grade_code("Bravo! Retenez l'usage des `$` pour récupérer les éléments nommés et des crochets `[...]` pour récupérer les éléments non-nommés!")

grade_this({
  lobjs <- ls(envir = .envir_result)
  if (!exists("fruits", envir = .envir_result) ) {
    fail("Le vecteur `fruits` n'existe pas.")
  }
  if (!identical(.result,.solution)) {
    fail("Ce résultat n'est pas ce que j'attendais. Vous n'avez pas à effectuer le calcul vous même, juste à utiliser `+`...")
  }
  if (identical(.result,.solution)) {
    pass("Bravo ! Vous avez bien créé le vecteur `fruits` en sommant `pommes` et `bananes`. Avez-vous remarqué comme NA+quelque chose donne NA?...")
  }
})

grade_this({
  lobjs <- ls(envir = .envir_result)
  set.seed(33)
  x=rnorm(1000,3,2)
  moyenne <- mean(x)
  variance <- var(x)
  quantile90p <- quantile(x,0.9)
  objs=ls(envir=.envir_result)
  if (!all(c("moyenne","variance","quantile90p") %in% objs)) {
    fail("Certains des objets attendus (`moyenne`, `variance`, `quantile90p`) n'existent pas.")
  }
  if(!identical(moyenne, .envir_result[["moyenne"]])){
    fail("La moyenne n'a pas la valeur attendue.")
  }
  if(!identical(variance, .envir_result[["variance"]])){
    fail("La variance n'a pas la valeur attendue.")
    }
  if(!identical(quantile90p, .envir_result[["quantile90p"]])){
    fail("Le quantile d'ordre 90% n'a pas la valeur attendue.")
  }
  pass("C'est tout bon!")
})
```
