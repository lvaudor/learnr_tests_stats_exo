---
title: "Tests statistiques"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
css: "www/style_tuto_learnr.css"
description: >
  Learn how to filter observations in a data frame. Use `filter()` to extract
  observations from a data frame, and use `&`, `|`, and `!` to write logical
  tests.
---

```{r setup, include=FALSE}
library(learnr)
library(gradethis)

Sys.setlocale("LC_ALL", "fr_FR.UTF-8")
gradethis_setup()
 
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(gridExtra)
library(purrr)
library(magrittr)
library(gganimate)
library(infer)
source("scripts/utils2.R")
#knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)

chateauxEtBoulots=read.csv("http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/datasets/chateauxEtBoulots.csv",
                           header=TRUE, sep=",")
broceliande=read.csv("datasets/broceliande.csv",sep=";", header=T)
potions=read.csv("datasets/potions.csv",sep=";", header=T)
```

## 1. Introduction 


![](www/grimoire.png){width=400px}
Ce tutoriel est √† la fois un **support de cours** et un **deck d'exercices** visant √† expliquer les tests statistiques et leur mise en pratique sous R (notamment tests de Student et test du Chi-2). 

Les explications et donn√©es d'exemple pour ce tutoriel proviennent d'un ouvrage en ligne, **le Grimoire: Contes et stats R** <a href="http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/_book/intro.html" target="_blank">disponible ici</a> (voir notamment le Chapitre 4 *Etablir le lien entre deux variables: tests d‚Äôhypoth√®se*). 

Vous pouvez √©galement y trouver des chapitres portant sur d'**autres m√©thodes classiques en statistique** (description simple de variables, estimateurs, intervalles de confiance, mod√®les de **r√©gression**, **analyse de la variance**, **mod√®le lin√©aire g√©n√©ralis√©**).

## --- 1.1 Exercices de code

Ce document rassemble un certain nombre d'exercices, qui sont de **deux types**.

- Des exercices de type **QCM**.
- Des exercices de type **code**.

Dans ce deuxi√®me type d'exercice, vous pourrez **modifier du code** dans une fen√™tre (fond jaune p√¢le) qui est l'√©quivalent d'un **√©diteur** (tr√®s simplifi√©) de code R. Pour **ex√©cuter** les lignes de code, vous pouvez vous placer dessus et faire **Ctrl+Enter**. Le r√©sultat s'affichera dans une fen√™tre (fond rose p√¢le) en-dessous qui est l'√©quivalent d'une **console** R.

La consigne pour cet exercice d'exemple est la suivante:

Calculez le produit de a et b (qui ont √©t√© pr√©alablement d√©finis dans l'environnement).

```{r decouvre_exos-setup}
a=33
b=29
```

```{r decouvre_exos, exercise=TRUE}
produit=___
produit
```

```{r decouvre_exos-solution}
produit=a*b
produit
```

Dans ce tutoriel l'**environnement R est propre √† chaque exercice**, et je le pr√©pare pour qu'il contienne les **objets** (par exemple jeux de donn√©es) et les **packages**  n√©cessaires, install√©s et charg√©s.


## --- 1.2 Exercices type QCM

```{r usages_R}
question("Que venez-vous faire ici?",
        answer("comprendre les tests statistiques", correct=TRUE),
        answer("pr√©parer mes prochaines vacances"),
        answer("mettre en oeuvre des tests statistiques avec R", correct=TRUE),
        answer("apprendre √† faire de d√©licieuses lasagnes"),
        incorrect="Seules deux de ces propositions sont correctes",
        correct="Oui! C'est dommage pour le reste mais ce n'est pas de notre ressort aujourd'hui...",
        allow_retry=TRUE
)
```

## --- 1.3 Broc√©liande

<table>
<col width="40%">
<col width="60%">
<tr><td>
<img src="www/enchanted_tree.png"  width="200px"></img>
</td>
<td>
Le jeu de donn√©es `broceliande` recense (en terme d'individus) un certain nombre d'arbres de la for√™t de Broc√©liande ainsi que (en terme de variables):
                                             
- `age`: leur √¢ge, en ann√©es
- `espece`: leur esp√®ce (ch√™ne, ch√¢taignier, h√™tre ou sapin)
- `hauteur`: leur hauteur, en cm
- `largeur`: leur largeur, en cm
- `gui`: le nombre de touffes de gui qui les affecte
- `enchantement`: la pr√©sence d'un enchantement sur cet arbre (TRUE ou FALSE)
- `fees`: le nombre de f√©es qui habitent cet arbre
- `lutins`: le nombre de lutins qui habitent cet arbre
- `perlimpinpin`: la quantit√© de poudre de perlimpinpin dans sa s√®ve (en $\mu$g/L)

</td></tr></table>

Le jeu de donn√©es `broceliande` est disponible en ligne [√† cette adresse](datasets/broceliande.csv).

```{r broceliande_pres}
broceliande=read.csv("http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/datasets/broceliande.csv",
                     header=TRUE,sep=";")
str(broceliande)
```

L'objectif des tests d'hypoth√®se est de d√©terminer si un **effet observ√© √† l'√©chelle de l'√©chantillon** r√©sulte d'un **effet r√©el √† l'√©chelle de la population**, autrement dit, il s'agit de d√©terminer si l'effet observ√© est **significatif** et non pas simplement li√© √† l'**al√©a d'√©chantillonnage**.


## --- 1.4 Ch√¢teaux et Boulots

<table>
  <col width="40%">
  <col width="60%">
<tr><td>
<img src="www/chateau.png"  width="200px"></img>
</td>
<td>
Le jeu de donn√©es `chateauxEtBoulots` recense (en terme d'individus) un certain nombre de personnes du pays Fantaisie ainsi que (en terme de variables)

- `activite`: leur activit√© (la royaut√©, la chevalerie, les enchantements ou la magie noire),
- `genre`: leur genre (f√©minin ou masculin),
- `region`: leur r√©gion (Bois-Jolis,Montage-Sombre ou Flots-Blancs)
- `tenue`: leur couleur de tenue (noire, grise, bleue, verte, ou rose).

</td>
</tr>
</table>
  
  
Le jeu de donn√©es `chateauxEtBoulots` est disponible en ligne [√† cette adresse](datasets/chateauxEtBoulots.csv).

```{r chateauxEtBoulots_pres}
chateauxEtBoulots=read.csv("http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/datasets/chateauxEtBoulots.csv",
                           header=TRUE, sep=",")
str(chateauxEtBoulots)
```


## 2. Test de Student 

Bien qu'il existe une multitude de tests d'hypoth√®ses (test de Student, test du Chi-2, test de Mann-Whitney, etc. en fonction du type de donn√©es et de la probl√©matique consid√©r√©s), la l**ogique et les "m√©canismes d'interpr√©tation" sont toujours les m√™mes**.

Je vais commencer par expliquer dans le d√©tail les principes et les m√©canismes sous-jacents √† un test statistique, en d√©veloppant l'exemple d'un test particulier, le **test de Student** ou **t-test**.


## --- 2.1 Principe

<div class="encadre">
Le **t-test** (ou **test de Student**) est con√ßu pour tester des **diff√©rences de moyennes entre deux groupes**.
</div>

<table>
<col width="20%">
<col width="80%">
<tr><td>
<img src="www/balance.png"  width="300"></img>
</td>
<td>

Par exemple, on cherche √† caract√©riser la **quantit√© de poudre de perlimpinpin contenue par la s√®ve d'un arbre** en fonction de la **nature enchant√©e ou non** de celui-ci. On peut commencer par d√©crire le lien entre ces deux variables √† l'aide d'une table et d'une figure montrant les distributions de la variable `perlimpinpin` par groupe.
</td>
</tr>
</table>
  
Ci-dessous on calcule la moyenne et la m√©diane de quantit√© de perlimpinpin pour chacun des groupes, ainsi que l'√©cart-type par groupe et l'effectif (n).
 
```{r, echo=TRUE}
broceliande %>%
  group_by(enchantement) %>%
  summarise(moy=mean(perlimpinpin),
            med=median(perlimpinpin),
            sd=sd(perlimpinpin),
            n=n()) 
```  
  
On peut tracer les distributions √† l'aide d'un graphique appel√© "violinplot" (qui correspond, grosso modo, aux densit√©s de probabilit√© repr√©sent√©es √† la verticale).

  
```{r boxplot_ench_perl_2, fig.width=5, fig.height=3, echo=TRUE}
ggplot(broceliande, aes(x=enchantement, y=perlimpinpin))+
  geom_violin(fill="forestgreen", alpha=0.5)+
  geom_point(data=broceliande %>% group_by(enchantement) %>% summarise(perlimpinpin=mean(perlimpinpin)),
             shape=3,size=3,stroke=1)
```


A la vue du graphique et du tableau ci-dessus, on a bien l'impression que la quantit√© de perlimpinpin est plus importante pour les arbres enchant√©s que pour les autres, mais...


<!-- ```{r inference_mentale} -->
<!-- question("Est-ce un effet r√©el ou simplement d√ª au hasard, √† votre avis? (plusieurs r√©ponses possibles)", -->
<!--     answer("Probablement li√© au hasard, car les distributions des deux groupes ne sont pas totalement disjointes."), -->
<!--     answer("Probablement li√© au hasard, car les √©chantillons sont de tailles tr√®s in√©gales."), -->
<!--     answer("Probablement r√©el, car les tailles d'√©chantillon sont relativement importantes", correct=TRUE), -->
<!--     incorrect="Eh non, a priori les tailles d'√©chantillon iraient plut√¥t dans le sens d'un effet r√©el", -->
<!--     correct="Oui! Vu les tailles d'√©chantillon importantes et l'allure de la distribution par groupe, on peut penser que l'effet observ√© est r√©el.", -->
<!--     allow_retry=TRUE -->
<!-- ) -->
<!-- ``` -->

Avec la question ci-dessus, j'essaie de vous montrer que vous √™tes capables de faire des **inf√©rences "non-statistiques"**, qui font en fait appel √† des notions de taille d'√©chantillon et de distribution des donn√©es qui sont fondamentales pour la r√©alisation de tests statistiques.

La r√©alisation de tests statistiques correspond √† une **formalisation du raisonnement** que vous avez pu faire dans la question pr√©c√©dente, et qui permet de **quantifier** la probabilit√© que l'effet observ√© soit d√ª au hasard.

## --- 2.2 Formalisation

Je formalise mon probl√®me par le mod√®le suivant:

<div class="encadre">
$perlimpinpin$ a une distribution $\mathcal{N}(\mu_e,\sigma_e)$ pour les
arbres enchant√©s, et $\mathcal{N}(\mu_f,\sigma_f)$ pour les autres.
</div>

On se place ici dans une formalisation du **t-test de Welch** (une variante plus robuste du test de Student "classique", puisqu'elle ne fait pas l'hypoth√®se que les variances sont √©gales dans les deux groupes). 

Je d√©finis mon hypoth√®se:

<div class="encadre">
$H_0:\{\mu_e=\mu_f\}$
</div>

Selon cette hypoth√®se, il n'y a **pas de diff√©rence r√©elle** de moyenne entre les deux groupes (m√™me si, de facto, il y a une diff√©rence *observ√©e*).

Autrement dit, l'hypoth√®se que je cherche √† tester statistiquement est celle selon laquelle "la quantit√© de perlimpinpin moyenne n'est pas diff√©rente selon les groupes" ...

alors que mon hypoth√®se au sens "scientifique" √©tait plut√¥t l'hypoth√®se inverse puisque j'ai en r√©alit√© l'intention de prouver que l'enchantement **a un effet significatif sur la quantit√© de perlimpinpin**!... Il faut donc faire attention √† ne pas se m√©langer les pinceaux...

Consid√©rons la statistique suivante:

<div class="encadre">

$$
T=\frac{\bar X_e-\bar X_f}{\sqrt{\frac{s_e^2}{n_e}+\frac{s_f^2}{n_f}}}=\frac{\bar X_e-\bar X_f}{\sqrt{eqm_e+eqm_f}}
$$
</div>

o√π

- $\bar{X_e}$ et $\bar{X_f}$ sont les estimateurs de la moyenne (par groupe)
- $s_e$ et $s_f$ sont les estimateurs des √©carts-types (par groupe)
- $n_e$ et $n_f$ sont les effectifs observ√©s (par groupe)

Cette m√©trique est donc d'autant plus grande (en valeur absolue) que

- l'√©cart entre moyennes est important,
- les tailles d'√©chantillons sont importantes,
- la variance au sein de chaque groupe est petite.

<div class="encadre">
Si notre hypoth√®se $H_0$ √©tait vraie alors cette statistique $T$ devrait suivre une **distribution de Student** avec $\nu$ degr√©s de libert√©.
</div>

(Il s'agit d'un r√©sultat **math√©matique**, que je ne d√©montrerai pas ici!)

Le **param√®tre $\nu$** correspond √†:

$$
\nu=\frac{\left(\frac{s_e^2}{n_e}+\frac{s_f^2}{n_f}\right)^2}{{(\frac{s_e^2}{n_e})}^2\frac{1}{n_e-1}+{(\frac{s_f^2}{n_f})}^2 \frac{1}{n_f-1}}=\frac{(eqm_e+eqm_f)^2}{eqm_e^2\ \frac{1}{n_e-1}+eqm_f^2\ \frac{1}{n_f-1}}
$$




On peut calculer les valeurs $t_{obs}$ (valeur de $T$ pour les observations) et $\nu$ "√† la main":

```{r broc_ttest_calc_alamain, echo=TRUE}
broc_test=broceliande %>%
  group_by(enchantement) %>%
  summarise(m=mean(perlimpinpin),
            s2=sd(perlimpinpin)^2,
            n=n()) %>%
  mutate(eqm=s2/n,
         w=1/(n-1)) %>%
  mutate(eqmw=w*eqm^2)
valeurs_obs=broc_test %>%
  summarise(t_obs=diff(m)/sqrt(sum(eqm)),
            nu=sum(eqm)^2/sum(eqmw))
valeurs_obs
```

Voici la distribution de Student √† $\nu$=`r round(valeurs_obs$nu)` degr√©s de libert√© -i.e. **la distribution que $T$ doit suivre, th√©oriquement, si l'hypoth√®se $H_0$ est vraie**- et voil√† (en rouge) comment se situe la **valeur observ√©e de T pour notre √©chantillon ($t_{obs}$)**:

```{r broc_ttest_calc_infer_et_obs, echo=FALSE, fig.width=5, fig.height=2.5}
library(infer)
 mytest <- broceliande %>%
   t_test(formula = perlimpinpin ~ enchantement, order=c(TRUE,FALSE))

 model=broceliande %>%
   specify(perlimpinpin ~ enchantement) 
 theory=model %>%
   assume(distribution="t")
 stat= model %>% calculate(stat="t", order=c("TRUE","FALSE")) %>% pull(stat)
 
visualise(theory)+shade_p_value(stat,direction="greater") 
```

Comme on peut le voir sur ce graphique, la valeur que l'on observe pour T est tr√®s "excentr√©e" par rapport √† la distribution th√©orique sous hypoth√®se $H_0$.

En effet, la **probabilit√© d'observer une valeur au moins aussi excentr√©e (√† droite ou √† gauche) sous hypoth√®se $H_0$**, ou **p-value** est de `r round(stat,2)`


C'est cette **valeur de probabilit√©** qui est repr√©sent√©e par la **surface colori√©e en rose** dans le graphique ci-dessus.

Si la p-value est particuli√®rement petite, cela tend √† prouver que **la valeur observ√©e de $T$ est peu probable sous hypoth√®se $H_0$**. Cela am√®ne donc √† remettre en question l'hypoth√®se (et non l'observation!!).

<div class="encadre">En dessous d'un certain seuil pour cette probabilit√© (par exemple, $\alpha=5$\%), on d√©cide de rejeter l'hypoth√®se $H_0$. Dans ce cas on peut affirmer qu'il existe bien un effet significatif de `enchantement` sur `perlimpinpin` ü™Ñ.</div>

La valeur $\alpha$ est souvent, par convention, 5\% (il arrive aussi que l'on voie 10\%, 1\%, etc.). Cette valeur **n'est pas un rep√®re absolu** (si vous √™tes √† 5.1\% plut√¥t qu'√† 4.9\% √ßa ne devrait pas *fondamentalement* changer votre conclusion...).

```{r ttest_questions2}
question("Cochez les affirmations correctes",
         answer("La valeur de la statistique observ√©e d√©pend des donn√©es", correct=TRUE),
         answer("La distribution de la statistique T sous hypoth√®se H0 est une distribution de Student et ne d√©pend pas des donn√©es"),
         answer("La p-value peut prendre des valeurs entre -1 et 1."),
         answer("Plus la p-value est proche de 0, plus il y a des chances que l'on rejette H0" , correct=TRUE),
         answer("Si la p-value est √©gale √† 0.04, alors je peux rejeter H0 au seuil de 1% et conclure √† un effet significatif"),
         answer ("Si la p-value est √©gale √† 0.1, alors je peux rejeter H0 au seuil de 5% et conclure √† un effet significatif"),
         incorrect="Attention il y a quelques petits pi√®ges: la loi de Student a un param√®tre (qui d√©pend bien des donn√©es), une p-value est une probabilit√© et ne peut pas √™tre n√©gative, et 0.04 correspond √† 4% et 0.1 √† 10%",
         correct="Oui! C'est une gymnastique mentale mais une fois que c'est int√©gr√© c'est comme le v√©lo...",
         allow_retry=TRUE
)
```

## --- 2.3 Erreurs

Quand on r√©alise un test d'hypoth√®se, on l'interpr√®te g√©n√©ralement en fonction d'une valeur seuil $\alpha$.

Cette valeur seuil $\alpha$ abord√©e pr√©c√©demment correspond en fait √† un risque d'erreur de type I que l'on est "pr√™t √† accepter".

<div class="encadre">
Faire une **erreur de type I**, √ßa consiste √† **rejeter l'hypoth√®se nulle alors qu'elle est vraie** (c'est-√†-dire, affirmer qu'une diff√©rence est significative alors que ce n'est pas le cas). Le **risque d'erreur de type I** est souvent not√© $\alpha$

Faire une **erreur de type II**, au contraire, √ßa consiste √† **ne pas rejeter l'hypoth√®se nulle alors qu'elle est fausse** (c'est-√†-dire, ne pas conclure que la diff√©rence est significative alors qu'elle existe vraiment). Le **risque d'erreur de type II** est souvent not√© $\beta$.
</div>


Cas            |   $H_0$ rejet√©e (üôÇ "effet")| $H_0$ accept√©e (üòê "pas d'effet")
---------------|-----------------------------|---------------
$H_0$ vraie (pas d'effet) | üî¥ erreur de type I ($\alpha$) | üü¢ CORRECT
$H_0$ fausse (effet)      | üü¢ CORRECT                     | üî¥ erreur de type II ($\beta$)

La **puissance d'un test** est √©gale √† 1-$\beta$ i.e. elle correspond √† la probabilit√© de d√©tecter un effet quand il existe ($H_0$ est fausse et on rejette $H_0$).

Quand on choisit de r√©aliser un test avec un risque $\alpha$ particuli√®rement bas, alors le risque $\beta$ est particuli√®rement √©lev√©, c'est √† dire qu'on le fait au d√©triment de la **puissance** du test (c'est-√†-dire que plus on minimise le risque de dire qu'il y a un effet alors qu'il n'y en a pas, plus on maximise le risque de "passer √† c√¥t√©" d'un effet qui existe).

```{r ttest_questions3}
question("Cochez les affirmations correctes",
          answer("Les tests statistiques permettent de ne jamais faire d'erreur d'interpr√©tation"),
          answer("Quand on choisit le seuil alpha pour r√©aliser un test, on choisit en fait le risque d'erreur de type I", correct=TRUE),
          answer("beta=1-alpha"),
          answer("G√©n√©ralement, on cherche √† valider H0"),
          answer("G√©n√©ralement, on cherche √† 'prouver' qu'il existe un effet de X sur Y", correct=TRUE), 
          incorrect="Malheureusement, recourir √† un test statistique ne nous pr√©munit pas de faire des erreurs d'interpr√©tation et il faut toujours faire des compromis entre les risques d'erreur de type I et de type II",
          correct="Oui! Vous avez apparemment compris les grands principes donc on va pouvoir passer √† la pratique :-)",
          allow_retry=TRUE)
```

## --- 2.4 Pratique

En pratique, pour r√©aliser un t-test sous R, on n'a pas besoin de faire √† la main toutes les √©tapes du calcul de la statistique T et de $\nu$ d√©taill√© pr√©cedemment (ouf!). Il existe *√©videmment* des fonctions dans R pour faciliter la t√¢che.

La fonction de base est `t.test()`:

```{r myttest,type="essentiel", echo=TRUE}
mytest=t.test(perlimpinpin~enchantement, data=broceliande)
print(mytest)
```

Et voil√† ‚ö°! comme vous pouvez le constater, cela prend plus longtemps d'expliquer le principe et l'interpr√©tation d'un test de Student que de le r√©aliser avec R!


Plusieurs informations s'affichent:

- le **nom du test** (t-test de Welch pour deux √©chantillons)
- certains **√©l√©ments** qui interviennent dans le calcul d'une **p-value** (valeur de m√©trique observ√©e t, nombre de degr√©s de libert√© df)
- la **p-value** elle-m√™me
- l'hypoth√®se alternative (et non pas $H_0$) selon laquelle la diff√©rence de moyenne entre les groupes **n'est pas** √©gale √† 0
- un **intervalle de confiance √† 95\% pour cette diff√©rence de moyenne**
- les **moyennes estim√©es** pour chaque groupe


On retrouve notamment la valeur $t_{obs}$, $\nu$ (nombre de degr√©s de libert√©) et la p-value calcul√©s "√† la main" dans le paragraphe pr√©c√©dent, et qui nous permettent de **rejeter l'hypoth√®se H0** i.e. conclure que **l'enchantement de l'arbre a bien un effet sur la quantit√© de perlimpinpin qu'il produit**.


```{r ttest_exo1-setup}
library(dplyr)
library(ggplot2)
broceliande_chenes=read.csv("http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/datasets/broceliande.csv",
                     header=TRUE,sep=";") %>%
  filter(espece=="chene")
```


<table>
  <col width="40%">
  <col width="60%">
  <tr><td>


Consid√©rez √† nouveau le jeu de donn√©es `broceliande`. Nous allons nous int√©resser √† la relation entre quantit√© de perlimpinpin et enchantement pour la sous-population des **ch√™nes**.
  
Examinez les effectifs de ch√™ne dans chaque groupe (arbres enchant√©s ou non) et r√©alisez le test qui permet de tester l'hypoth√®se $H_0$ selon laquelle **l'enchantement de l'arbre n'a pas d'effet sur la quantit√© de perlimpinpin qu'il produit**.

L'environnement ci-dessous est pr√©par√© de sorte que y sont disponibles:

- üíæ le jeu de donn√©es broceliande_chenes
- üì¶ le package dplyr (charg√©)
- üì¶ le package ggplot2 (charg√©)

</td><td>
```{r, echo=FALSE, fig.height=3, fig.width=3}
broceliande_chenes=read.csv("datasets/broceliande.csv",sep=";", header=T) %>% 
  filter(espece=="chene")
ggplot(broceliande_chenes,
       aes(x=enchantement, y=perlimpinpin))+geom_boxplot(fill="lightgreen")+ggtitle("Ch√™nes")
```
</td></tr></table>


```{r ttest_exo1, exercise=TRUE}
# Examinez les effectifs
___(broceliande_chenes$enchantement)
# R√©alisez le test
t.test(______~______, data=____)
```


```{r ttest_exo1-solution}
# Examinez les effectifs
table(broceliande_chenes$enchantement)
# R√©alisez le test
t.test(perlimpinpin~enchantement, data=broceliande_chenes)
```

```{r ttest_questions1}
question("Le r√©sultat du test ci-dessus permet de ",
         answer("rejeter l'hypoth√®se H_0: donc la quantit√© de perlimpinpin n'est pas li√©e √† l'enchantement des ch√™nes"),
         answer("accepter l'hypoth√®se H_0: donc la quantit√© de perlimpinpin n'est pas li√©e √† l'enchantement des ch√™nes"),
         answer("rejeter l'hypoth√®se H_0: donc la quantit√© de perlimpinpin est li√©e √† l'enchantement des ch√™nes", correct=TRUE),
         answer("accepter l'hypoth√®se H_0: donc la quantit√© de perlimpinpin est li√©e √† l'enchantement des ch√™nes"),
         incorrect="Non! attention au 'sens' de l'hypoth√®se H_0...",
         correct="Oui! Il √©tait assez simple d'inf√©rer cet effet ne serait-ce que visuellement -et du fait des effectifs importants de ch√™nes-",
         allow_retry=TRUE
)
```


## --- 2.5 Pratique avec infer


<table><col width="20%"><col width="80%">
<tr>
<td>![](www/logo_infer.png){width=200px}
</td><td>
Outre la fonction t.test de "base", il est √©galement possible d'utiliser le package "infer" pour r√©aliser un t-test "√† la tidyverse" (i.e. selon une syntaxe qui d√©compose les √©tapes du calcul/raisonnement)</td>
</td></tr></table>

Voici une mani√®re de d√©composer la r√©alisation d'un test:


<table><col width="60%"><col width="40%">
<tr><td>
```{r, fig.width=5, fig.height=5}
# Installer DiagrammeR si necessaire
if (!requireNamespace("DiagrammeR", quietly = TRUE)) {
  install.packages("DiagrammeR")
}

# Charger le package
library(DiagrammeR)

# Creer le diagramme
grViz('digraph infer_workflow {
  graph [layout = dot, rankdir = TB]

  # Definir les n≈ìuds
  node [shape = rectangle, style = filled, color = lightblue]
  A [color="#bae1ff",label = "Donn√©es\n(tableau initial)"]
  B [color="#bae1ff", label = "Donn√©es + Mod√®le Y~X"]
  H [color="#ffb3ba",label = "p-value"]
  I [style=solid,color=black,label = "Rejet ou non de H0"]
  
  
  subgraph cluster_EF {
    label = "";
    style = filled;
    color = gray;
    node [shape = rectangle, style = filled, color = yellow];
  E [color="#ffdfba", label = "Distribution de la statistique\nsous hypoth√®se nulle"]
  F [color="#ffdfba", label = "Statistique observ√©e"]
 
  }

  # Ajouter les connexions principales
  A -> B  [label = "specify()"]

  B -> E  [label = "assume()"]
  B -> F  [label = "calculate()"]
  F -> H
  E -> H  [label = "get_p_value()"]
  H -> I  [label = "Interpr√©ter la p-value"]


}')

```
</td><td>

Ainsi, pour r√©aliser un test de Student avec `infer`, on suit les √©tapes suivantes:

- partant des <span style="background-color: #bae1ff; padding: 2px;">donn√©es</span>:
- sp√©cifier ("specify") le <span style="background-color: #bae1ff; padding: 2px;">mod√®le</span> (donn√©es, variables X et Y) 
- en supposant ("assume") l'hypoth√®se nulle vraie, calculer la <span style="background-color: #ffdfba; padding: 2px;">distribution de la statistique</span>
- calculer ("calculate") la <span style="background-color: #ffdfba; padding: 2px;">statistique observ√©e</span>
- obtenir la <span style="background-color: #ffb3ba; padding: 2px;">p-value</span> ("get_p_value") et l'interpr√©ter

</td></tr></table>


```{r myttest_infer, echo=TRUE}
mod_et_hyp=broceliande %>%
  specify(perlimpinpin ~ enchantement) 
dist_null=mod_et_hyp %>%
  assume(distribution="t")
stat_obs=mod_et_hyp %>%
  calculate(stat="t", order=c("TRUE","FALSE")) %>%
  pull(stat)
p_value=get_p_value(dist_null,stat_obs, direction="greater")
p_value
```

<small> Remarque: on a ici une valeur de p-value tr√®s l√©g√®rement diff√©rente de celle qu'on obtenait avec la fonction `t.test`. La raison √† cela est que `t.test` r√©alise par d√©faut un t-test de Welch et que la fonction `infer` r√©alise un t-test de Student classique. </small>
 
Enfin, on peut utiliser ces √©l√©ments pour **visualiser la distribution de la statistique de Student sous hypoth√®se nulle** et la **valeur de la statistique observ√©e** (et ainsi visualiser la **p-value**).


```{r visualise_dist_null_et_pvalue, fig.width=5, fig.height=2.5, echo=TRUE}
visualize(dist_null)+
  shade_p_value(stat, direction="greater")
```
 
## 3. Validit√© du t-test 

Refaisons un pas en arri√®re... Jusqu'√† pr√©sent j'ai suppos√© que les donn√©es permettaient de r√©aliser un test de Student. Mais qu'en est-il vraiment?        

Revenons aux conditions n√©cessaires √† la validit√© du t-test.

Rappelez-vous comment j'ai sp√©cifi√© mon mod√®le:

<div class="encadre">
$perlimpinpin$ a une distribution $\mathcal{N}(\mu_e,\sigma_e)$ pour les arbres enchant√©s, et $\mathcal{N}(\mu_f,\sigma_f)$ pour les autres.
</div>

Ainsi, on conna√Æt la distribution de la statistique $T$ sous hypoth√®se $H_0$, mais aussi sous r√©serve que la distribution de $perlimpinpin$ dans chaque groupe d√©fini par $enchantement$ soit **normale** (i.e. gaussienne).

## --- 3.1 Distribution normale / gaussienne

<table>
  <col width="60%">
  <col width="40%">
  <tr><td>
Une distribution normale ou gaussienne est une **distribution sym√©trique, centr√©e sur sa moyenne, et dont la forme est d√©termin√©e par son √©cart-type**. 
</td><td>
![](www/chapeaux.png)
</td>
</tr></table>

Voici par exemple les distributions de deux variables g√©n√©r√©es selon une gaussienne (√† gauche) et une loi non-gaussienne (√† droite). 


```{r, fig.height=5, fig.width=8,echo=FALSE}
# Charger les packages n√©cessaires
library(patchwork)

# G√©n√©rer des donn√©es
set.seed(123)
n <- 1000
data <- data.frame(
  variable = c(rnorm(n, mean = 0, sd = 1), rexp(n, rate = 1)),
  type = rep(c("Gaussienne", "Non-Gaussienne"), each = n)
)

# Graphique pour la densit√© de la variable gaussienne
plot_gaussian_density <- ggplot(data[data$type == "Gaussienne", ],
                                aes(x = variable)) +
  geom_density(fill = "skyblue", alpha = 0.5) +
  labs(title = "Densit√© gaussienne", x = "Valeur", y = "Densit√©") +
  theme_minimal()

# Graphique pour la densit√© de la variable non-gaussienne
plot_non_gaussian_density <- ggplot(data[data$type == "Non-Gaussienne", ],
                                    aes(x = variable)) +
  geom_density(fill = "coral", alpha = 0.5) +
  labs(title = "Densit√© non-gaussienne", x = "Valeur", y = "Densit√©") +
  theme_minimal()

# Graphique pour le boxplot de la variable gaussienne
plot_gaussian_boxplot <- ggplot(data[data$type == "Gaussienne", ], aes(x = type, y = variable)) +
  geom_boxplot(fill = "skyblue", alpha = 0.5) +
  labs(title = "Boxplot gaussien", x = "", y = "Valeur") +
  theme_minimal()

# Graphique pour le boxplot de la variable non-gaussienne
plot_non_gaussian_boxplot <- ggplot(data[data$type == "Non-Gaussienne", ], aes(x = type, y = variable)) +
  geom_boxplot(fill = "coral", alpha = 0.5) +
  labs(title = "Boxplot non-gaussien", x = "", y = "Valeur") +
  theme_minimal()

# Combiner les graphiques en une grille 2x2
combined_plot <- (plot_gaussian_density + plot_non_gaussian_density) / 
  (plot_gaussian_boxplot + plot_non_gaussian_boxplot)

# Afficher le graphique
print(combined_plot)
```

Examinez quelques exemples de situations ci-dessous o√π l'on essaie d'**√©valuer visuellement** si la distribution de la variable √† expliquer dans chacun des groupes peut √™tre consid√©r√©e comme **gaussienne ou non**.


```{r distribs_cases, fig.width=8, fig.height=5}
p1= ggplot(broceliande %>% filter(espece == "chene"),
           aes(x = enchantement, y = perlimpinpin)) +
  geom_boxplot(width=0.3)+
  geom_violin(fill="lightgreen", alpha=0.5)+
  labs(title = "a) perlimpinpin~enchantement (ch√™nes)", x = "enchantement", y = "perlimpinpin") +
  theme_minimal()


p2= ggplot(broceliande %>% filter(espece == "sapin"),
           aes(x = enchantement, y = perlimpinpin)) +
  geom_boxplot(width=0.3)+
  geom_violin(fill="darkgreen", alpha=0.5)+
  labs(title = "b) perlimpinpin~enchantement (sapins)", x = "enchantement", y = "perlimpinpin") +
  theme_minimal()


p3= ggplot(broceliande,
           aes(x = as.factor(gui>0), y = hauteur)) +
  geom_boxplot(width=0.3)+
  geom_violin(fill="#70A9A9", alpha=0.5)+
  labs(title = "c) hauteur~gui", x = "pr√©sence-absence de gui", y = "hauteur de l'arbre") +
  theme_minimal()


p4= ggplot(broceliande,
           aes(x = enchantement, y = fees)) +
  geom_boxplot(width=0.3)+
  geom_violin(fill="#A03090", alpha=0.5)+
  labs(title = "d) fees~enchantement", x = "enchantement", y = "fees") +
  theme_minimal()

# Combiner les graphiques en une grille 2x2
combined_plot <- (p1+p2) /  (p3+p4)

# Afficher le graphique
print(combined_plot)
```


```{r question_gaussiennes}
question("Pour chaque situation ci-dessus, cochez si vous pensez que la distribution de la variable √† expliquer dans chaque groupe est gaussienne ou non",
         answer("a) perlimpinpin~enchantement (ch√™nes): gaussienne", correct=TRUE),
         answer("a) perlimpinpin~enchantement (ch√™nes): non-gaussienne"),
         answer("b) perlimpinpin~enchantement (sapins): gaussienne"),
         answer("b) perlimpinpin~enchantement (sapins): non-gaussienne", correct=TRUE),
         answer("c) hauteur~gui: gaussienne"),
         answer("c) hauteur~gui: non-gaussienne", correct=TRUE),
         answer("d) fees~enchantement: gaussienne"),
         answer("d) fees~enchantement: non-gaussienne", correct=TRUE),
         incorrect="Hmm, √ßa se discute, mais je n'aurais pas dit cela...",
         correct="Bravo! Vous avez l'oeil pour rep√©rer les distributions gaussiennes!",
         allow_retry=TRUE
)
```

## --- 3.2 Effectifs 

Que faire alors si l'on est dans un cas o√π manifestement la distribution par groupes n'est pas gaussienne?

<div class="encadre">
Dans certains cas, on peut consid√©rer que les **effectifs par groupe sont assez √©lev√©s pour que la condition de distribution gaussienne ne soit pas strictement n√©cessaire √† la validit√© du test**. En effet, la distribution de $T$ tend vers une distribution de Student √† $\nu$ degr√©s de libert√© asymptotiquement: si les tailles d'√©chantillon sont "suffisamment grandes" la distribution de la statistique sera proche de cette distribution th√©orique. Cela d√©coule du **Th√©or√®me Central Limite** qui dit que la distribution de la moyenne d'un √©chantillon tend vers une gaussienne lorsque la taille de l'√©chantillon est grande.
</div>

<small>üí°Souvent, on consid√®re que s'il y a plus de 30 individus par groupe, alors on peut consid√©rer que la distribution de $T$ est suffisamment proche d'une distribution de Student pour que le test soit valide ‚úÖ ... mais il s'agit d'une r√®gle empirique et non d'une r√®gle math√©matique! </small>

Cette id√©e de "distribution asymptotique" est assez compliqu√©e √† comprendre math√©matiquement, mais nous pouvons ce genre de ph√©nom√®ne par une **simulation**... 


<!-- <table> -->
<!-- <col width="50%"> -->
<!-- <col width="50%"> -->
<!-- <tr><td> -->
<!-- On proc√®de √† plusieurs tirages de X, de taille $N=10$ (donc plut√¥t **petits**), dans une distribution non-gaussienne (distribution repr√©sent√©e en vert). Pour chacun de ces √©chantillons, on calcule la moyenne (droite violette). -->
<!-- </td><td> -->
<!-- ```{r dist1, echo=FALSE, fig.height=2, fig.width=5, cache=TRUE} -->
<!-- anim=distribution_of_mean(N=10, mu=2, sigma=1, -->
<!--                      nIter=10000,nImages=20, -->
<!--                      show=c(TRUE,TRUE,TRUE,FALSE), -->
<!--                      model="lnorm", -->
<!--                      animate=FALSE) -->
<!-- anim -->
<!-- ``` -->
<!-- </td></tr></table> -->
<!-- <table> -->
<!-- <col width="50%"> -->
<!-- <col width="50%"> -->
<!-- <tr><td> -->
<!-- On fait cela de tr√®s, tr√®s nombreuses fois (ici, 10 000 fois), et du coup on peut observer la distribution de moyennes afich√©e ci-contre... -->
<!-- </td><td> -->
<!-- ```{r anim1, echo=FALSE, fig.height=2, fig.width=5, cache=TRUE} -->
<!-- anim=distribution_of_mean(N=10, mu=2, sigma=1, -->
<!--                      nIter=10000,nImages=20, -->
<!--                      show=c(TRUE,TRUE,FALSE,FALSE), -->
<!--                      model="lnorm", -->
<!--                      animate=TRUE) -->
<!-- anim=anim+transition_states(frame,transition_length=1,state_length=1) -->
<!-- anim_save(animation=anim, filename="www/anim1.gif") -->
<!-- ``` -->
<!-- ![](www/anim1.gif) -->
<!-- </td></tr></table> -->

<!-- <table> -->
<!-- <col width="50%"> -->
<!-- <col width="50%"> -->
<!-- <tr><td> -->
<!-- Bon, ben, du coup, on ne sait pas tr√®s bien quelle loi suit la moyenne: (visiblement, une loi diff√©rente de la loi $\mathcal{N}(\mu,\sigma)$):  -->
<!-- blabal </td><td> -->
<!-- ```{r anim2, echo=FALSE, fig.height=2, fig.width=5} -->
<!-- distribution_of_mean(N=30, mu=5, sigma=1, -->
<!--                      nIter=10000,nImages=20, -->
<!--                      show=c(TRUE,FALSE,TRUE,TRUE), -->
<!--                      model="lnorm", -->
<!--                      animate=FALSE) -->
<!-- ``` -->
<!-- </td> -->
<!-- <td> -->


<!-- ```{r anim_lnorm_smallN_2, echo=FALSE, fig.height=2, fig.width=5} -->
<!-- distribution_of_mean(N=10, mu=2, sigma=1, -->
<!--                      nIter=10000,nImages=20, -->
<!--                      show=c(TRUE,FALSE,TRUE,TRUE), -->
<!--                      model="lnorm", -->
<!--                      animate=FALSE) -->
<!-- ``` -->
<!-- </td></tr></table> -->


<!-- Que se passe-t-il pour une taille d'√©chantillon plus importante? -->

<!-- ```{r anim5_bis, echo=FALSE, fig.height=2, fig.width=5, cache=TRUE} -->
<!-- anim=distribution_of_mean(N=50, mu=2, sigma=1, -->
<!--                      nIter=10000,nImages=20, -->
<!--                      show=c(TRUE,TRUE,FALSE,FALSE), -->
<!--                      model="lnorm") -->
<!-- anim=anim+transition_states(frame,transition_length=1,state_length=1) -->
<!-- anim_save(animation=anim, filename="anim3.gif") -->
<!-- ``` -->
<!-- ![](anim3.gif) -->
<!-- Par la barbe de Merlin! On dirait que plus **$N$ est grand**, et plus la distribution se **rapproche de la loi $\mathcal{N}(\mu,\sigma)$**! -->

<!-- ```{r anim6, echo=FALSE, fig.height=2, fig.width=5} -->
<!-- distribution_of_mean(N=50, mu=2, sigma=1, -->
<!--                      nIter=10000,nImages=20, -->
<!--                      show=c(TRUE,FALSE,TRUE,TRUE), -->
<!--                      model="lnorm", -->
<!--                      animate=FALSE) -->
<!-- ``` -->

<!-- Ce r√©sultat, c'est ce qu'on appelle le **Th√©or√®me Central Limite**... Ce th√©or√®me stipule que "**pour N suffisamment grand**", la distribution de la moyenne $\bar X$ (moyenne d'une variable $X$ ayant une distribution **quelconque**, une **moyenne $\mu$** et un **√©cart-type $\sigma$**) est **$\mathcal{N}(\mu,\sigma/\sqrt{N})$**. -->




Que se passe-t-il si ce n'est pas le cas? (... et en l'occurrence, **ce n'est pas le cas**). Voyez plut√¥t, si l'on r√©aliste un test de Shapiro-Wilk pour tester la normalit√© des donn√©es (pour chaque groupe), ce test rejette l'hypoth√®se de distribution normale de perlimpinpin pour les arbres non-enchant√©s:

```{r shapiro}
perlimpinpin_enchantes=broceliande %>% filter(enchantement==TRUE) %>% pull(perlimpinpin)
perlimpinpin_nonenchantes=broceliande %>% filter(enchantement==FALSE) %>% pull(perlimpinpin)

shapiro.test(perlimpinpin_enchantes)
shapiro.test(perlimpinpin_nonenchantes)
```


En fait, comme dans le cas du **Th√©or√®me Central Limite**, quand bien m√™me l'hypoth√®se de normalit√© des r√©sidus ne serait pas respect√©e, la distribution de $T$ tend bien vers une distribution de Student √† $\nu$ degr√©s de libert√© **pour des tailles d'√©chantillon "suffisamment grandes"**.

Tout le sel de la situation consiste √† estimer la valeur pour laquelle on estime que la taille d'√©chantillon est "suffisamment grande" (ce seuil √©tant d'autant plus √©lev√© que la distribution des r√©sidus est √©loign√©e de la distribution normale) pour pouvoir appliquer le t-test quand bien-m√™me l'hypoth√®se de normalit√© ne serait pas respect√©...

Le package `infer` permet  de travailler assez facilement **non pas sur une distribution th√©orique de la statistique $T$** (reposant, donc, sur un mod√®le de distribution suppos√©) mais sur la **distribution observ√©e de $T$ quand on r√©alise des permutations**.

Le principe des permutations r√©alis√©es ici est de r√©aliser de nombreuses fois l'op√©ration suivante:

- √©tiqueter au hasard les individus selon les **modalit√©s de la variable d√©finissant les groupes** (et selon les effectifs observ√©s)
- calculer la **statistique $T$** pour ce jeu de donn√©es (g√©n√©r√©, donc, sous hypoth√®se que la variable qui d√©finit le groupe et la r√©ponse quantitative soient ind√©pendants)

On obtient ainsi la **distribution de la statistique $T$ sous hypoth√®se d'ind√©pendance** pour les distributions observ√©es.

```{r infer_permutations_ttest, fig.width=5, fig.height=2.5}
# permutations=broceliande %>%
#   specify(perlimpinpin ~ enchantement) %>%
#   hypothesize(null="independence") %>%
#   generate(reps=1000,type="permute") %>%
#   calculate(stat="t", order=c(FALSE,TRUE)) %>%
#   visualize(method="simulation",
#             obs_stat=t_obs,
#             direction="two_sided")

```

Ici on constate que la significativit√© du r√©sultat ne fait pas de doute!

## --- 3.3 infer

```{r}
# Installer DiagrammeR si necessaire
if (!requireNamespace("DiagrammeR", quietly = TRUE)) {
  install.packages("DiagrammeR")
}

# Charger le package
library(DiagrammeR)

# Creer le diagramme
grViz('digraph infer_workflow {
  graph [layout = dot, rankdir = TB]

  # Definir les n≈ìuds
  node [shape = rectangle, style = filled, color = lightblue]
  A [color="#bae1ff",label = "Donn√©es\n(tableau initial)"]
  B [color="#bae1ff", label = "Donn√©es + Mod√®le Y~X"]
  C [color="#ffffb9", label = "Hypoth√®se nulle\nH0"]
  D [color="#ffffb9", label = "Donn√©es permut√©es"]
  H [color="#ffb3ba",label = "p-value"]
  I [style=solid,color=black,label = "Rejet ou non de H0"]
  
  
  subgraph cluster_EF {
    label = "";
    style = filled;
    color = gray;
    node [shape = rectangle, style = filled, color = yellow];
  E [color="#ffdfba", label = "Distribution de la statistique\nsous hypoth√®se nulle"]
  F [color="#ffdfba", label = "Statistique observ√©e"]
 
  }

  # Ajouter les connexions principales
  A -> B  [label = "specify()"]

  B -> C  [label = "hypothesize()"]
  C -> D  [style = dashed, label = "generate()"]
  D -> E  [style = dashed, label="calculate()"]
 
  
  B -> F  [label = "calculate()"]
  F -> H
  E -> H  [label = "get_p_value()"]
  H -> I  [label = "Interpr√©ter la p-value"]


}')

```



## 4. Test du Chi-2 


R√©visons (suite √† ce que l'on a vu sur le test de Student) le prrincipe g√©n√©ral d'un test d'hypoth√®se *param√©trique*:

<div class="encadre">
- On consid√®re un **mod√®le statistique** d√©crivant nos donn√©es
- On consid√®re une certaine **hypoth√®se** $H_0$ concernant les param√®tres du mod√®le
- On consid√®re une **m√©trique $S$** (il s'agit d'une *variable al√©atoire*), dont la nature d√©pend du test r√©alis√©.
-  On calcule sa **distribution th√©orique** en se basant sur le mod√®le assorti de l'hypoth√®se $H_0$.
- On calcule la **valeur prise par $S$ pour les observations**: on obtient ainsi la mesure **$S_{obs}$**. $S_{obs}$ est une *r√©alisation* de la variable $S$.
- On regarde **o√π se place $S_{obs}$ par rapport √† distribution th√©orique de $S$**: on calcule la probabilit√© que $S$ soit au moins aussi "extr√™me" que $S_{obs}$. C'est cette probabilit√© qui constitue la **p-value**.
</div>

Dans tous les cas, lorsque l'on r√©alise un test statistique, il faut √™tre tr√®s attentif aux √©l√©ments suivants:

- Les hypoth√®ses du mod√®le sous-jacent au test (par exemple, pour le t-test, la variable d'int√©r√™t doit √™tre de distribution gaussienne. En revanche, le fait que vous utilisiez le t-test de Welch et non de Student vous permet de supposer que la variance est diff√©rente dans les deux groupes)
- La nature de l'hypoth√®se $H_0$ (Si vous vous trompez sur la nature de cette hypoth√®se, alors vous vous tromperez dans la mani√®re dont vous interpr√©tez les r√©sultats du test!)


## --- 4.1 Principe du test du Chi-2

Int√©ressons-nous au jeu de donn√©es `chateauxEtBoulots`, et au lien entre `genre` et `activite`.



```{r chateauxEtBoulots_barplot_1, fig.width=6,fig.height=2}
ggplot(chateauxEtBoulots,aes(x=activite))+
  geom_bar(aes(fill=genre))
```

```{r chateauxEtBoulots_barplot_2, fig.width=6,fig.height=2}
ggplot(chateauxEtBoulots,aes(x=activite))+
  geom_bar(aes(fill=genre),position="fill")
```


## --- 4.2 Tableau de contingence

Nous avons-vu que la comparaison entre le tableau des effectifs crois√©s **observ√©s** et des effectifs **attendus** sous hypoth√®se d'ind√©pendance pouvait nous renseigner sur un lien √©ventuel entre les deux variables consid√©r√©es.

En l'occurrence, on peut noter les **effectifs observ√©s** dans chacune des J cases du tableau $\bar {N_i}$ et les **effectifs attendus** $N_i$.

A partir de ces deux tableaux, une **statistique du Chi-2** (√©crite $\chi^2$) peut √™tre calcul√©e et utilis√©e pour tester l'hypoth√®se d'ind√©pendance entre les deux variables cat√©gorielles. La statistique du $\chi^2$ correspond √† :

$$\chi^2=\sum_{i=1}^{J}\frac{(\bar{N_i}-N_i)^2}{N_i}$$
**Sous hypoth√®se d'ind√©pendance**, et sous r√©serve que les effectifs par case soient suffisamment importants, cette statistique $\chi^2$ est cens√©e suivre une **distribution du $\chi^2$ √† $J-2$ degr√©s de libert√©**.

C'est ce r√©sultat (math√©matique) qui permet de fournir une **p-value** qui correspond √† la **probabilit√© d'obtenir une valeur de $\chi^2$ sup√©rieure √† celle qui est calcul√©e sur les observations**.

## --- 4.3 Pratique

Faire un test du Chi-2 sous R

<table>
  <col width="40%">
  <col width="60%">
  <tr>
  <td><img src="www/trone.png" width="200px" </td>
  <td>Examinons par exemple le jeu de donn√©es `chateauxEtBoulots` et plus particuli√®rement le lien entre le genre et l'activit√© de nos personnages de contes de f√©e... On sait gr√¢ce aux **tableaux de contingence** comment **d√©crire le lien** entre ces deux variables cat√©gorielles par un **tableau de contingences**. Voyons maintenant comment l'on peut **tester la significativit√© de ce lien**.</td>
  </tr>
</table>

```{r chateauxEtBoulots_chisq_en_pratique}
montest=chisq.test(table(chateauxEtBoulots$genre,chateauxEtBoulots$activite))
print(montest)
```

Ici la p-value est tr√®s petite, montrant (comme on s'y attendait) que les deux variables **ne sont pas ind√©pendantes**.

On peut examiner plus avant les √©l√©ments renvoy√©s par ce test de la mani√®re suivante:

```{r chisqtest_elems}
names(montest)
```

On retrouve ainsi, entre autres choses, des √©l√©ments d'information concernant

- les **effectifs observ√©s**


```{r chisqtest_observed}
montest$observed
```

- les **effectifs attendus sous hypoth√®se d'ind√©pendance**

```{r chisqtest_expected}
montest$expected
```


<div class="exo">

Consid√©rez le tableau `chateauxEtBoulots` et les variables `tenue` et `region`. Les tendances en terme de couleurs de tenue sont-elles bien significativement diff√©rentes en fonction de la r√©gion de Fantaisie?...

```{r, echo=FALSE, results=FALSE}
chisq.test(table(chateauxEtBoulots$tenue,chateauxEtBoulots$region))
```

</div>


## 5 Validit√© du test du Chi-2 

## ----- 5.1 Petits effectifs

Un test du $\chi^2$ est construit en supposant que **les effectifs $\bar N_j$ sont "suffisants")**. Ainsi, quand certaines cases du tableau de contingence comprennent trop peu d'individus, appliquer un test du $\chi^2$ peut causer un "warning" stipulant que *l'approximation du $\chi^2$ peut √™tre incorrecte*.

Conid√©rons par exemple un sous-jeu de donn√©es de `chateauxEtBoulots` rassemblant uniquement les individus de noble extraction, et int√©ressons-nous au lien entre leur genre et leur couleur de tenue:

```{r chateauxEtBoulots_princiere}
tenue_princiere=filter(chateauxEtBoulots, activite=="royaute") %>%
  mutate(tenue=as.factor(as.vector(tenue)))

table_tenue_princiere=table(tenue_princiere$genre, tenue_princiere$tenue)
table_tenue_princiere


chisq.test(table_tenue_princiere)
```

Ici, on a bien des effectifs r√©duits qui causent le renvoi d'un warning...

Le package `infer` permet, dans ce genre de situation, de **calculer une p-value en passant par des permutations** plut√¥t qu'en utilisant la distribution de la statistique du $\chi^2$ qui s'applique pour des effectifs observ√©s importants.

Le principe des permutations r√©alis√©es ici est de r√©aliser de nombreuses fois l'op√©ration suivante:

- √©tiqueter au hasard les individus selon les **modalit√©s du premier facteur** (et selon les effectifs observ√©s pour celui-ci)
- √©tiqueter au hasard les individus selon les **modalit√©s du second facteur** (et selon les effectifs observ√©s pour celui-ci)
- calculer la **statistique du $chi^2$** pour ce jeu de donn√©es (g√©n√©r√©, donc, sous hypoth√®se que les deux facteurs soient ind√©pendants)

On obtient ainsi la **distribution de la statistique $chi^2$ sous hypoth√®se d'ind√©pendance** pour les effectifs observ√©s de l'un et l'autre facteur (aussi d√©s√©quilibr√©s et faibles soient-ils).

La valeur observ√©e du $\chi^2$ sur les donn√©es est la suivante:

```{r infer_obs_chisq, warning=FALSE, message=FALSE}
obs_chisq=tenue_princiere %>%
  chisq_test(formula=tenue~genre) %>%
  select(statistic) %>%
  pull()

obs_chisq # pareil que chisq.test(tenue_princiere)$statistic, mais obtenu via infer

```

On simule 1000 jeux de donn√©es diff√©rents √† partir du jeu de donn√©es `sim_princiere` selon la m√©thode expliqu√©e ci-dessus. On obtient ainsi 1000 valeurs de la statistique $\chi^2$:

```{r infer_generate_chisq}
sim_princiere=tenue_princiere %>%
  specify(tenue~genre) %>%
  hypothesize(null="independence") %>%
  generate(reps=1000, type="permute") %>%
  calculate(stat="Chisq")

head(sim_princiere)
```

Cela permet de d√©crire la distribution de la statistique $\chi^2$ et d'en d√©duire une p-value:

```{r sim_princiere_visu, fig.width=5, fig.height=2.5}
# resume_sim_princiere=
#   sim_princiere %>%
#   mutate(case=stat<obs_chisq) %>%
#   group_by(case) %>%
#   summarise(prop=n()) %>%
#   mutate(prop=prop/1000)
# resume_sim_princiere
# 
# sim_princiere%>%
#   visualize(obs_stat=obs_chisq, direction="greater")
```

On obtient ainsi la distribution r√©elle de la statistique du $\chi^2$ sous hypoth√®se d'ind√©pendance, et la valeur de la p-value . Ici, on remarque que la p-value est quasiment inchang√©e selon la m√©thode de calcul (distribution th√©orique ou par permutations)! On n'est pas en mesure d'affirmer que la couleur de tenue des princes et princesses d√©pend de leur genre.


<div class="exo">

On reprend l'exercice pr√©c√©dent...

Consid√©rez le tableau `chateauxEtBoulots` et les variables `tenue` et `region`. Les tendances en terme de couleurs de tenue sont-elles bien significativement diff√©rentes en fonction de la r√©gion de Fantaisie?...

R√©pondez √† cette question √† l'aide du package `infer` et des permutations, de sorte de ne pas √™tre g√™n√© par le faible effectif dans certaines cases du tableau de contingence...

```{r, echo=FALSE, results=FALSE}
# obs_chisq=tenue_princiere %>%
#   chisq_test(formula=tenue~region) %>%
#   select(statistic) %>%
#   pull()
# 
# obs_chisq # pareil que chisq.test(tenue_princiere)$statistic, mais obtenu via infer
# sim_princiere=tenue_princiere %>%
#   specify(tenue~genre) %>%
#   hypothesize(null="independence") %>%
#   generate(reps=1000, type="permute") %>%
#   calculate(stat="Chisq")
# 
# head(sim_princiere)
# resume_sim_princiere=
#   sim_princiere %>%
#   mutate(case=stat<obs_chisq) %>%
#   group_by(case) %>%
#   summarise(prop=n()) %>%
#   mutate(prop=prop/1000)
# resume_sim_princiere
# 
# sim_princiere%>%
#   visualize(obs_stat=obs_chisq, direction="greater")
```

</div>



## ANNEXE

```{r}
# Installer DiagrammeR si necessaire
if (!requireNamespace("DiagrammeR", quietly = TRUE)) {
  install.packages("DiagrammeR")
}

# Charger le package
library(DiagrammeR)

# Creer le diagramme
grViz('digraph infer_workflow {
  graph [layout = dot, rankdir = TB]

  # Definir les n≈ìuds
  node [shape = rectangle, style = filled, color = lightblue]

  C [color="orange", label = "Hypoth√®se nulle\nH0"]
  D [color="orange", label = "Donn√©es permut√©es"]
  G [label = "Graphique \nde la distribution sous H0\nde la statistique observ√©e"]
  H [label = "p-value"]
  I [color = seagreen,label = "Interpr√©tation :\nRejeter ou non H0"]


  subgraph cluster_AB {
    label = "";
    style = solid;
    color = gray;
    node [shape = rectangle, style = filled, color = pink];
    A [label = "Donn√©es\n(tableau initial)"]
    B [label = "Donn√©es + Mod√®le Y~X"]
  }
  
  subgraph cluster_EF {
    label = "";
    style = solid;
    color = gray;
    node [shape = rectangle, style = filled, color = yellow];
 E [color="yellow", label = "Distribution de la statistique\nsous hypoth√®se nulle"]
  F [color="yellow", label = "Statistique observ√©e"]
 
  }

  # Ajouter les connexions principales
  A -> B  [label = "<B>specify()</B> : Sp√©cifier le mod√®le"]
  B -> C  [label = "hypothesize(): Formuler l hypoth√®se nulle"]
  C -> D  [style = dashed, label = "generate() : G√©n√©rer les donn√©es sous H0 (permutation/bootstrap)"]
  D -> E  [style = dashed, label="Calculer la distribution de la statistique sous H0"]
 
  B -> E  [label = "assume(): calculer la distribution de la statistique sous H0,\nen supposant les conditions de validit√© remplies"]
  E -> H  [label = "calculate(): calculer la statistique observ√©e"]
  F -> H
  B -> F  [label = "calculate()"]
  E -> G  [label = "calculate()\nCalculer la statistique"]
  G -> H [label = "visualize()\nVisualiser la distribution de la statistique sous hypoth√®se nulle."]
  H -> I  [label = "get_p_value()\nEstimer la p-value"]


}')

```

